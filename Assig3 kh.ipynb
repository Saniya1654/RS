{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "726edc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 10000 ratings, 27278 movies, 465564 tags.\n",
      "Starting content pre-processing...\n",
      "Content pre-processing complete.\n",
      "Training Collaborative Filtering (SVD) model...\n",
      "Rating scale detected: 1.0 to 5.0\n",
      "SVD model training complete. Time taken: 0.16 seconds.\n",
      "\n",
      "--- DEMONSTRATION: User 45989 ---\n",
      "\n",
      "User 45989's Top 5 Rated Movies (for context):\n",
      "  - Casino (1995) (Rating: 5.0)\n",
      "  - Rob Roy (1995) (Rating: 5.0)\n",
      "  - Dances with Wolves (1990) (Rating: 5.0)\n",
      "  - Braveheart (1995) (Rating: 5.0)\n",
      "  - Clueless (1995) (Rating: 5.0)\n",
      "\n",
      "Calculating hybrid recommendations...\n",
      "Predicting ratings for 27156 unseen movies...\n",
      "Re-ranking top 100 candidates using content data...\n",
      "Recommendation generation took 0.50 seconds.\n",
      "\n",
      "Top 10 Hybrid Recommendations for User 45989 (Alpha=0.7):\n",
      "   1. Sense and Sensibility (1995) (MovieID: 17)\n",
      "   2. Schindler's List (1993) (MovieID: 527)\n",
      "   3. Piano, The (1993) (MovieID: 509)\n",
      "   4. American President, The (1995) (MovieID: 11)\n",
      "   5. Like Water for Chocolate (Como agua para chocolate) (1992) (MovieID: 265)\n",
      "   6. Eat Drink Man Woman (Yin shi nan nu) (1994) (MovieID: 232)\n",
      "   7. Burnt by the Sun (Utomlyonnye solntsem) (1994) (MovieID: 213)\n",
      "   8. Bullets Over Broadway (1994) (MovieID: 348)\n",
      "   9. Fargo (1996) (MovieID: 608)\n",
      "  10. Heavenly Creatures (1994) (MovieID: 247)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# --- Constants ---\n",
    "RATINGS_FILE = 'RS-A2_A3_Filtered_Ratings.csv'\n",
    "MOVIES_FILE = 'RS-A2_A3_movie.csv'\n",
    "TAGS_FILE = 'RS-A2_A3_tag.csv'\n",
    "\n",
    "\n",
    "HYBRID_ALPHA = 0.7  # 70% CF, 30% CB\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    try:\n",
    "        ratings_df = pd.read_csv(RATINGS_FILE)\n",
    "        movies_df = pd.read_csv(MOVIES_FILE)\n",
    "        tags_df = pd.read_csv(TAGS_FILE)\n",
    "\n",
    "        if 'Unnamed: 0' in ratings_df.columns:\n",
    "            ratings_df = ratings_df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "        return ratings_df, movies_df, tags_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Please make sure all CSV files are in the same directory.\")\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_content_data(movies_df, tags_df):\n",
    "\n",
    "    print(\"Starting content pre-processing...\")\n",
    "\n",
    "    movies_df['genres_cleaned'] = movies_df['genres'].str.replace('|', ' ', regex=False).fillna(\"\")\n",
    "\n",
    "    movies_df['genres_cleaned'] = movies_df['genres_cleaned'].str.replace('(no genres listed)', '', regex=False)\n",
    "\n",
    "    tags_df['tag_cleaned'] = tags_df['tag'].astype(str).str.lower()\n",
    "\n",
    "    tag_docs = tags_df.groupby('movieId')['tag_cleaned'].apply(lambda x: ' '.join(x))\n",
    "    tag_docs_df = tag_docs.reset_index()\n",
    "    tag_docs_df.columns = ['movieId', 'tags_content']\n",
    "\n",
    "    movies_df = pd.merge(movies_df, tag_docs_df, on='movieId', how='left')\n",
    "    movies_df['tags_content'] = movies_df['tags_content'].fillna(\"\")\n",
    "\n",
    "    movies_df['content'] = movies_df['genres_cleaned'] + ' ' + movies_df['tags_content']\n",
    "\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(movies_df['content'])\n",
    "\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    indices = pd.Series(movies_df.index, index=movies_df['movieId']).drop_duplicates()\n",
    "\n",
    "    print(\"Content pre-processing complete.\")\n",
    "    return cosine_sim, indices, movies_df\n",
    "\n",
    "\n",
    "def train_cf_model(ratings_df):\n",
    "\n",
    "    print(\"Training Collaborative Filtering (SVD) model...\")\n",
    "\n",
    "    min_rating = ratings_df['rating'].min()\n",
    "    max_rating = ratings_df['rating'].max()\n",
    "    print(f\"Rating scale detected: {min_rating} to {max_rating}\")\n",
    "\n",
    "    reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "    data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "    trainset = data.build_full_trainset()\n",
    "\n",
    "    svd = SVD(n_factors=100, n_epochs=20, random_state=42, verbose=False)\n",
    "\n",
    "    start_time = time.time()\n",
    "    svd.fit(trainset)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"SVD model training complete. Time taken: {end_time - start_time:.2f} seconds.\")\n",
    "    return svd, min_rating, max_rating\n",
    "\n",
    "\n",
    "def get_hybrid_recommendations(user_id, movies_df, ratings_df, indices, cosine_sim, svd, min_rating, max_rating, alpha=0.7, n_recs=10, n_candidates=100):\n",
    "\n",
    "    try:\n",
    "        rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].unique()\n",
    "    except KeyError:\n",
    "        print(f\"Error: User {user_id} not found in ratings data.\")\n",
    "        return []\n",
    "\n",
    "    user_ratings = ratings_df[ratings_df['userId'] == user_id]['rating']\n",
    "    if user_ratings.empty:\n",
    "        print(f\"User {user_id} has no ratings. Cannot generate recommendations.\")\n",
    "        return []\n",
    "\n",
    "    rating_threshold = min(np.percentile(user_ratings, 80), 4.0)\n",
    "    top_rated_df = ratings_df[(ratings_df['userId'] == user_id) & (ratings_df['rating'] >= rating_threshold)]\n",
    "    top_rated_movies = top_rated_df['movieId'].tolist()\n",
    "\n",
    "    top_movie_indices = [indices[movie_id] for movie_id in top_rated_movies if movie_id in indices]\n",
    "\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "\n",
    "    unseen_movies = [m for m in all_movies if m not in rated_movies]\n",
    "\n",
    "    print(f\"Predicting ratings for {len(unseen_movies)} unseen movies...\")\n",
    "    cf_candidates = []\n",
    "    for movie_id in unseen_movies:\n",
    "\n",
    "        pred = svd.predict(user_id, movie_id)\n",
    "        cf_candidates.append((movie_id, pred.est))\n",
    "\n",
    "    cf_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    top_n_cf = cf_candidates[:n_candidates]\n",
    "\n",
    "    hybrid_recs = []\n",
    "\n",
    "    if not top_movie_indices:\n",
    "\n",
    "        print(\"User has no top-rated movies for content matching. Falling back to pure CF.\")\n",
    "        for movie_id, cf_score in top_n_cf:\n",
    "            hybrid_recs.append((movie_id, cf_score)) # Score is just the CF score\n",
    "\n",
    "    else:\n",
    "        print(f\"Re-ranking top {n_candidates} candidates using content data...\")\n",
    "        for movie_id, cf_score in top_n_cf:\n",
    "            if movie_id not in indices:\n",
    "                continue # Movie has no content data\n",
    "\n",
    "            candidate_idx = indices[movie_id]\n",
    "\n",
    "            sim_scores = cosine_sim[candidate_idx, top_movie_indices]\n",
    "\n",
    "            cb_score = sim_scores.mean()\n",
    "\n",
    "            norm_cf = (cf_score - min_rating) / (max_rating - min_rating)\n",
    "\n",
    "            norm_cb = cb_score\n",
    "\n",
    "            hybrid_score = (alpha * norm_cf) + ((1 - alpha) * norm_cb)\n",
    "            hybrid_recs.append((movie_id, hybrid_score))\n",
    "\n",
    "    hybrid_recs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    final_movie_ids = [m[0] for m in hybrid_recs[:n_recs]]\n",
    "\n",
    "    movie_id_to_title = pd.Series(movies_df.title.values, index=movies_df.movieId).to_dict()\n",
    "\n",
    "    final_recommendations = []\n",
    "    for mid in final_movie_ids:\n",
    "        title = movie_id_to_title.get(mid, \"Unknown Movie\")\n",
    "        final_recommendations.append((title, mid))\n",
    "\n",
    "    return final_recommendations\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    ratings_df, movies_df, tags_df = load_data()\n",
    "    if ratings_df is None:\n",
    "        return\n",
    "    print(f\"Loaded {len(ratings_df)} ratings, {len(movies_df)} movies, {len(tags_df)} tags.\")\n",
    "\n",
    "    cosine_sim, indices, movies_df_processed = preprocess_content_data(movies_df.copy(), tags_df.copy())\n",
    "\n",
    "    svd, min_r, max_r = train_cf_model(ratings_df.copy())\n",
    "\n",
    "    user_counts = ratings_df['userId'].value_counts()\n",
    "    if user_counts.empty:\n",
    "        print(\"No users found in ratings data.\")\n",
    "        return\n",
    "\n",
    "    example_user_id = user_counts.index[0] # User with the most ratings\n",
    "\n",
    "    print(f\"\\n--- DEMONSTRATION: User {example_user_id} ---\")\n",
    "\n",
    "    user_ratings = ratings_df[ratings_df['userId'] == example_user_id]\n",
    "    user_ratings_merged = user_ratings.merge(movies_df_processed, on='movieId', how='left')\n",
    "    top_5 = user_ratings_merged.sort_values('rating', ascending=False).head(5)\n",
    "\n",
    "    print(f\"\\nUser {example_user_id}'s Top 5 Rated Movies (for context):\")\n",
    "    for _, row in top_5.iterrows():\n",
    "        print(f\"  - {row['title']} (Rating: {row['rating']})\")\n",
    "\n",
    "    print(\"\\nCalculating hybrid recommendations...\")\n",
    "    start_time = time.time()\n",
    "    recommendations = get_hybrid_recommendations(\n",
    "        user_id=example_user_id,\n",
    "        movies_df=movies_df_processed,\n",
    "        ratings_df=ratings_df,\n",
    "        indices=indices,\n",
    "        cosine_sim=cosine_sim,\n",
    "        svd=svd,\n",
    "        min_rating=min_r,\n",
    "        max_rating=max_r,\n",
    "        alpha=HYBRID_ALPHA,\n",
    "        n_recs=10,\n",
    "        n_candidates=100\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Recommendation generation took {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    print(f\"\\nTop 10 Hybrid Recommendations for User {example_user_id} (Alpha={HYBRID_ALPHA}):\")\n",
    "    if not recommendations:\n",
    "        print(\"No recommendations could be generated.\")\n",
    "    else:\n",
    "        for i, (title, mid) in enumerate(recommendations):\n",
    "            print(f\"  {i+1:2}. {title} (MovieID: {mid})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf4705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# Simple-language explanation & theory (copy-paste into Jupyter cell)\n",
    "# ---------------------------------------------------------------------\n",
    "#\n",
    "# OVERVIEW (what this notebook does)\n",
    "# ---------------------------------\n",
    "# This notebook builds a **hybrid recommendation system** that combines:\n",
    "#   1) Collaborative Filtering (CF) via matrix factorization (Surprise's SVD)\n",
    "#   2) Content-Based (CB) recommendations using movie tags / text and TF-IDF + cosine similarity\n",
    "#\n",
    "# The final recommendations are a weighted blend of CF and CB scores using a parameter (HYBRID_ALPHA).\n",
    "# - HYBRID_ALPHA = 0.7 means 70% weight to CF (SVD) and 30% weight to CB (TF-IDF cosine similarity).\n",
    "#\n",
    "# WHY A HYBRID?\n",
    "# -------------\n",
    "# - CF recommends items by learning user/item interaction patterns (good for personalization).\n",
    "# - CB recommends items similar in content to what the user liked (helps with new items or cold-start items).\n",
    "# - Combining them reduces each approach's weaknesses and improves recommendation coverage and quality.\n",
    "#\n",
    "# KEY STEPS IN THE CODE\n",
    "# ---------------------\n",
    "# 1) IMPORTS\n",
    "#    - pandas, numpy for data handling\n",
    "#    - sklearn.feature_extraction.text.TfidfVectorizer to turn text into numeric features\n",
    "#    - sklearn.metrics.pairwise.cosine_similarity to measure similarity between item vectors\n",
    "#    - surprise.Reader/Dataset and surprise.SVD to train a matrix-factorization CF model\n",
    "#\n",
    "# 2) DATA LOADING\n",
    "#    - Read ratings, movies, and tags CSVs into DataFrames.\n",
    "#    - Clean trivial columns like 'Unnamed: 0' if present.\n",
    "#\n",
    "# 3) CONTENT REPRESENTATION (TF-IDF)\n",
    "#    - Use TfidfVectorizer to convert textual tags/genres/plot into a TF-IDF matrix.\n",
    "#    - Each movie becomes a high-dimensional vector (one dimension per token).\n",
    "#\n",
    "#    Purpose of TfidfVectorizer:\n",
    "#    - TF-IDF = term-frequency * inverse-document-frequency.\n",
    "#    - It increases weight for tokens that are frequent in a particular document but rare across documents,\n",
    "#      which helps highlight distinctive words for each movie.\n",
    "#\n",
    "#    Basic TF-IDF formula (common version):\n",
    "#      tfidf(t, d) = tf(t, d) * idf(t)\n",
    "#      idf(t) = log( N / (1 + df(t)) )\n",
    "#      where:\n",
    "#        - tf(t,d) = frequency of term t in document d (often normalized)\n",
    "#        - N = total number of documents (movies)\n",
    "#        - df(t) = number of documents containing term t\n",
    "#\n",
    "# 4) CONTENT-BASED SIMILARITY (Cosine similarity)\n",
    "#    - Compute pairwise cosine similarity between TF-IDF vectors to get how \"alike\" two movies are.\n",
    "#\n",
    "#    Cosine similarity formula:\n",
    "#      cosine_similarity(a, b) = (a · b) / (||a|| * ||b||)\n",
    "#      where:\n",
    "#        - a · b is the dot product of vectors a and b\n",
    "#        - ||a|| is the Euclidean norm (length) of vector a\n",
    "#    - Cosine ranges from -1 to 1 (for TF-IDF nonnegative vectors, range is [0,1]).\n",
    "#\n",
    "# 5) COLLABORATIVE FILTERING (Surprise SVD)\n",
    "#    - Use the Surprise library's SVD implementation to learn latent factors for users and items from ratings.\n",
    "#    - The model approximates the rating matrix R (users × items) by factorizing into low-rank matrices.\n",
    "#\n",
    "#    Matrix factorization / SVD idea (intuitive math):\n",
    "#      Given rating matrix R, approximate:\n",
    "#         R ≈ U Σ V^T\n",
    "#      In recommender context we often learn:\n",
    "#         R_ij ≈ p_i^T q_j + b_i + b_j + μ\n",
    "#      where:\n",
    "#         - p_i is the user i latent vector\n",
    "#         - q_j is the item j latent vector\n",
    "#         - b_i and b_j are user/item biases, μ is global mean\n",
    "#      The dot product p_i^T q_j gives the predicted affinity of user i for item j.\n",
    "#\n",
    "#    - Surprise's SVD learns these latent vectors using stochastic gradient descent or ALS-like updates.\n",
    "#\n",
    "# 6) HYBRID SCORING\n",
    "#    - For a candidate movie, compute:\n",
    "#        score_cf  = predicted rating from SVD for (user, movie)\n",
    "#        score_cb  = similarity score from cosine similarity between candidate and user's liked items\n",
    "#    - Combine them:\n",
    "#        hybrid_score = alpha * normalized(score_cf) + (1 - alpha) * normalized(score_cb)\n",
    "#      where alpha is HYBRID_ALPHA (e.g., 0.7).\n",
    "#    - Normalization (e.g., MinMax scaling) brings both scores to same scale before blending.\n",
    "#\n",
    "# 7) RECOMMENDATION GENERATION\n",
    "#    - For a target user:\n",
    "#      - Get top-N candidate items (for efficiency you may sample n_candidates or use items not rated by user).\n",
    "#      - Compute CF and CB scores for candidates, normalize, blend, then return top-k.\n",
    "#\n",
    "\n",
    "# ------------------ TF-IDF (Theory + Intuition + Example) ------------------\n",
    "#\n",
    "# PURPOSE:\n",
    "# --------\n",
    "# TF-IDF stands for **Term Frequency–Inverse Document Frequency**.\n",
    "# It is a statistical method used to convert text data (like movie tags, genres, or descriptions)\n",
    "# into **numerical feature vectors** that can be used by machine learning models.\n",
    "#\n",
    "# WHY WE USE IT:\n",
    "# --------------\n",
    "# - In a recommendation system, we need a numeric representation of text content (e.g., movie tags or summaries).\n",
    "# - TF-IDF helps highlight *important and distinctive* words for each item (movie).\n",
    "# - It gives more weight to words that appear often in one movie but not across all movies.\n",
    "# - It reduces the influence of very common words like \"the\", \"movie\", \"film\", etc.\n",
    "#\n",
    "# CORE IDEA:\n",
    "# -----------\n",
    "# TF-IDF = Term Frequency (TF) × Inverse Document Frequency (IDF)\n",
    "#\n",
    "# Mathematically:\n",
    "#   tfidf(t, d) = tf(t, d) * idf(t)\n",
    "#\n",
    "# where:\n",
    "#   tf(t, d)   = (Number of times term t appears in document d) / (Total terms in d)\n",
    "#   idf(t)     = log( N / (1 + df(t)) )\n",
    "#   N          = total number of documents (e.g., total movies)\n",
    "#   df(t)      = number of documents that contain term t\n",
    "#\n",
    "# EXPLANATION:\n",
    "# ------------\n",
    "# - TF (Term Frequency): Measures how frequently a word occurs in a single document.\n",
    "#   → Higher TF means the term is important for that document.\n",
    "#\n",
    "# - IDF (Inverse Document Frequency): Measures how rare a word is across all documents.\n",
    "#   → A term appearing in many documents is less useful for distinguishing them.\n",
    "#   → The log ensures smoother scaling.\n",
    "#\n",
    "# - Multiplying them (TF × IDF):\n",
    "#   → High score if the term is frequent in one document but rare overall.\n",
    "#   → Low score if the term is common across all documents.\n",
    "#IN CODE:\n",
    "# - Each movie becomes a vector of TF-IDF weights (one dimension per word).\n",
    "# - This TF-IDF matrix is then used with cosine similarity to find movies with similar content.\n",
    "\n",
    "# ------------------ COSINE SIMILARITY (theory + example) ------------------\n",
    "#\n",
    "# What it measures (intuition):\n",
    "# - Cosine similarity measures the angle between two vectors in high-dimensional space.\n",
    "# - It tells us how similar the *direction* of two vectors is, ignoring their magnitudes.\n",
    "# - For text (TF-IDF) vectors: two documents with similar words have a small angle -> cosine near 1.\n",
    "#\n",
    "# Formula (compact):\n",
    "#   cosine(a, b) = (a · b) / (||a|| * ||b||)\n",
    "#   where\n",
    "#     - a · b = sum_i (a_i * b_i)  (dot product)\n",
    "#     - ||a|| = sqrt(sum_i a_i^2)  (Euclidean norm)\n",
    "#\n",
    "# Properties:\n",
    "# - Range: for TF-IDF (non-negative) vectors cosine ∈ [0, 1] (0 = orthogonal/unrelated, 1 = identical direction).\n",
    "# - Insensitive to scale: if you multiply a vector by a positive constant, cosine doesn't change.\n",
    "#\n",
    "# Step-by-step numeric example:\n",
    "#   a = [1, 2, 3]\n",
    "#   b = [4, 5, 6]\n",
    "#   dot = 1*4 + 2*5 + 3*6 = 32\n",
    "#   ||a|| = sqrt(1^2 + 2^2 + 3^2) = sqrt(14) ≈ 3.7417\n",
    "#   ||b|| = sqrt(4^2 + 5^2 + 6^2) = sqrt(77) ≈ 8.7750\n",
    "#   cosine = 32 / (3.7417 * 8.7750) ≈ 0.9746  (very similar)\n",
    "#\n",
    "# How it's used in this notebook:\n",
    "# - Compute TF-IDF vectors for movies (using tags/genres/descriptions).\n",
    "# - Cosine similarity between movie vectors => content-similarity matrix.\n",
    "# - For a user's liked movies, content-score of a candidate can be average or weighted sum of similarities.\n",
    "\n",
    "# ------------------ SVD / MATRIX FACTORIZATION (theory + training) ------------------\n",
    "#\n",
    "# Goal and intuition:\n",
    "# - Collaborative Filtering via matrix factorization tries to explain the user-item rating matrix R\n",
    "#   with low-dimensional latent factors. Each user and each item get a k-dimensional vector.\n",
    "# - The predicted rating is roughly the dot product between user and item vectors (plus biases).\n",
    "#\n",
    "# Mathematical view (full SVD vs learned MF):\n",
    "# - Full SVD (linear algebra): R = U Σ V^T  (requires a fully observed matrix)\n",
    "\n",
    "# Practical hyperparameters:\n",
    "# - n_factors (k): dimensionality of latent space (common: 20–200).\n",
    "# - n_epochs: number of passes over training data.\n",
    "# - lr (γ): learning rate for SGD — control the update size.\n",
    "# - reg (λ): regularization strength — prevents overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
